// This file is @generated by prost-build.
/// Contains all information necessary to create a new LogStream resource.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct CreateLogStreamRequest {
    /// Required. The parent resource of the created LogStream.
    /// The list of valid types of parent resources of LogStreams is up to the
    /// implementing server.
    /// Example: projects/123
    #[prost(string, tag = "1")]
    pub parent: ::prost::alloc::string::String,
}
/// A handle to a log (an ordered sequence of bytes).
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct LogStream {
    /// Structured name of the resource in the format:
    ///    {parent=**}/logstreams/{logstream_id}
    ///    Example: projects/123/logstreams/456-def
    /// Attempting to call the Byte Stream API's `Write` RPC with a LogStream's
    ///    `name` as the value for `ByteStream.Write.resource_name` is an error.
    #[prost(string, tag = "1")]
    pub name: ::prost::alloc::string::String,
    /// Resource name to pass to `ByteStream.Write` in the format:
    ///    {parent=**}/logstreams/{logstream_id}/{write_token}
    ///    Example: projects/123/logstreams/456-def/789-ghi
    /// Attempting to call the Byte Stream API's `Read` RPC with a LogStream's
    ///    `write_resource_name` as the value for `ByteStream.Write.resource_name`
    ///    is an error.
    ///
    /// `write_resource_name` is separate from `name` to ensure that only the
    /// intended writers can write to a given LogStream. Writers must address write
    /// operations to the `write_resource_name`, not the `name`, and must have
    /// permission to write LogStreams. `write_resource_name` embeds a secret token
    /// and should be protected accordingly; a mishandled `write_resource_name` can
    /// result in unintended writers corrupting the LogStream. Therefore, the field
    /// should be excluded from calls to any calls which retrieve LogStream
    /// metadata (i.e.: `GetLogStream`).
    ///
    /// Bytes written to this resource must to be readable when `ByteStream.Read`
    /// is called with the `name` resource.
    /// Reading a write_resource_name must return an INVALID_ARGUMENT error.
    #[prost(string, tag = "2")]
    pub write_resource_name: ::prost::alloc::string::String,
}
/// Generated client implementations.
pub mod log_stream_service_client {
    #![allow(
        unused_variables,
        dead_code,
        missing_docs,
        clippy::wildcard_imports,
        clippy::let_unit_value,
    )]
    use tonic::codegen::*;
    use tonic::codegen::http::Uri;
    /// #### Introduction
    ///
    /// The Log Stream API manages LogStream resources which are used to stream
    /// writes and reads of an ordered sequence of bytes of unknown eventual length.
    ///
    /// Note that this is an API Interface and not an API Service, per the definitions
    /// at: https://cloud.google.com/apis/design/glossary
    ///
    /// Log Stream API supports the reading of unfinalized LogStreams either by
    /// seeking or in "tail" mode, for example by end-users browsing to a build
    /// result UI interested in seeing logs from a build action as soon as they are
    /// (or as they become) available.
    ///
    /// Reads and Writes of LogStreams are done via the Byte Stream API:
    /// https://cloud.google.com/dataproc/docs/reference/rpc/google.bytestream
    /// https://github.com/googleapis/googleapis/blob/master/google/bytestream/bytestream.proto
    ///
    /// #### Writing LogStreams
    ///
    /// LogStreams are written to via the Byte Stream API's `Write` RPC. Bytes
    /// written to LogStreams are expected to be committed and available for reading
    /// within a reasonable period of time (implementation-defined). Committed bytes
    /// to a LogStream cannot be overwritten, and finalized LogStreams - indicated by
    /// setting `finish_write` field in the final WriteRequest - also cannot be
    /// appended to.
    ///
    /// When calling the Byte Stream API's `Write` RPC to write LogStreams, writers
    /// must pass the `write_resource_name` of a LogStream as
    /// `ByteStream.WriteRequest.resource_name` rather than the LogStream's `name`.
    /// Separate resource names for reading and writing allows for broadcasting the
    /// read resource name widely while simultaneously ensuring that only writer(s)
    /// with knowledge of the write resource name may have written bytes to the
    /// LogStream.
    ///
    /// #### Reading LogStreams
    ///
    /// Use the Byte Stream API's `Read` RPC to read LogStreams. When reading
    /// finalized LogStreams the server will stream all contents of the LogStream
    /// starting at `ByteStream.ReadRequest.read_offset`.
    ///
    /// When reading unfinalized LogStreams the server must keep the streaming
    /// `ByteStream.Read` RPC open and send `ByteStream.ReadResponse` messages as
    /// more bytes become available or the LogStream is finalized.
    ///
    /// #### Example Multi-Party Read/Write Flow
    ///
    /// 1. LogStream Writer calls `CreateLogStream`
    /// 2. LogStream Writer publishes `LogStream.name`
    /// 3. LogStream Writer calls `ByteStream.Write` with
    ///    `LogStream.write_resource_name` as
    ///    `ByteStream.WriteRequest.resource_name`,
    ///    `ByteStream.WriteRequest.finish_write`=false.
    /// 4. LogStream Reader(s) call `ByteStream.Read` with the published
    ///    `LogStream.name` as `ByteStream.ReadRequest.resource_name`.
    /// 5. LogStream Service streams all committed bytes to LogStream Reader(s),
    ///    leave the stream open.
    /// 6. LogStream Writer calls `ByteStream.Write` with
    ///    `LogStream.write_resource_name` as
    ///    `ByteStream.WriteRequest.resource_name`,
    ///    `ByteStream.WriteRequest.finish_write`=true.
    /// 7. LogStream Service streams all remaining bytes to LogStream Reader(s),
    ///    terminates the stream.
    #[derive(Debug, Clone)]
    pub struct LogStreamServiceClient<T> {
        inner: tonic::client::Grpc<T>,
    }
    impl LogStreamServiceClient<tonic::transport::Channel> {
        /// Attempt to create a new client by connecting to a given endpoint.
        pub async fn connect<D>(dst: D) -> Result<Self, tonic::transport::Error>
        where
            D: TryInto<tonic::transport::Endpoint>,
            D::Error: Into<StdError>,
        {
            let conn = tonic::transport::Endpoint::new(dst)?.connect().await?;
            Ok(Self::new(conn))
        }
    }
    impl<T> LogStreamServiceClient<T>
    where
        T: tonic::client::GrpcService<tonic::body::Body>,
        T::Error: Into<StdError>,
        T::ResponseBody: Body<Data = Bytes> + std::marker::Send + 'static,
        <T::ResponseBody as Body>::Error: Into<StdError> + std::marker::Send,
    {
        pub fn new(inner: T) -> Self {
            let inner = tonic::client::Grpc::new(inner);
            Self { inner }
        }
        pub fn with_origin(inner: T, origin: Uri) -> Self {
            let inner = tonic::client::Grpc::with_origin(inner, origin);
            Self { inner }
        }
        pub fn with_interceptor<F>(
            inner: T,
            interceptor: F,
        ) -> LogStreamServiceClient<InterceptedService<T, F>>
        where
            F: tonic::service::Interceptor,
            T::ResponseBody: Default,
            T: tonic::codegen::Service<
                http::Request<tonic::body::Body>,
                Response = http::Response<
                    <T as tonic::client::GrpcService<tonic::body::Body>>::ResponseBody,
                >,
            >,
            <T as tonic::codegen::Service<
                http::Request<tonic::body::Body>,
            >>::Error: Into<StdError> + std::marker::Send + std::marker::Sync,
        {
            LogStreamServiceClient::new(InterceptedService::new(inner, interceptor))
        }
        /// Compress requests with the given encoding.
        ///
        /// This requires the server to support it otherwise it might respond with an
        /// error.
        #[must_use]
        pub fn send_compressed(mut self, encoding: CompressionEncoding) -> Self {
            self.inner = self.inner.send_compressed(encoding);
            self
        }
        /// Enable decompressing responses.
        #[must_use]
        pub fn accept_compressed(mut self, encoding: CompressionEncoding) -> Self {
            self.inner = self.inner.accept_compressed(encoding);
            self
        }
        /// Limits the maximum size of a decoded message.
        ///
        /// Default: `4MB`
        #[must_use]
        pub fn max_decoding_message_size(mut self, limit: usize) -> Self {
            self.inner = self.inner.max_decoding_message_size(limit);
            self
        }
        /// Limits the maximum size of an encoded message.
        ///
        /// Default: `usize::MAX`
        #[must_use]
        pub fn max_encoding_message_size(mut self, limit: usize) -> Self {
            self.inner = self.inner.max_encoding_message_size(limit);
            self
        }
        /// Create a LogStream which may be written to.
        ///
        /// The returned LogStream resource name will include a `write_resource_name`
        /// which is the resource to use when writing to the LogStream.
        /// Callers of CreateLogStream are expected to NOT publish the
        /// `write_resource_name`.
        pub async fn create_log_stream(
            &mut self,
            request: impl tonic::IntoRequest<super::CreateLogStreamRequest>,
        ) -> std::result::Result<tonic::Response<super::LogStream>, tonic::Status> {
            self.inner
                .ready()
                .await
                .map_err(|e| {
                    tonic::Status::unknown(
                        format!("Service was not ready: {}", e.into()),
                    )
                })?;
            let codec = tonic::codec::ProstCodec::default();
            let path = http::uri::PathAndQuery::from_static(
                "/build.bazel.remote.logstream.v1.LogStreamService/CreateLogStream",
            );
            let mut req = request.into_request();
            req.extensions_mut()
                .insert(
                    GrpcMethod::new(
                        "build.bazel.remote.logstream.v1.LogStreamService",
                        "CreateLogStream",
                    ),
                );
            self.inner.unary(req, path, codec).await
        }
    }
}
/// Generated server implementations.
pub mod log_stream_service_server {
    #![allow(
        unused_variables,
        dead_code,
        missing_docs,
        clippy::wildcard_imports,
        clippy::let_unit_value,
    )]
    use tonic::codegen::*;
    /// Generated trait containing gRPC methods that should be implemented for use with LogStreamServiceServer.
    #[async_trait]
    pub trait LogStreamService: std::marker::Send + std::marker::Sync + 'static {
        /// Create a LogStream which may be written to.
        ///
        /// The returned LogStream resource name will include a `write_resource_name`
        /// which is the resource to use when writing to the LogStream.
        /// Callers of CreateLogStream are expected to NOT publish the
        /// `write_resource_name`.
        async fn create_log_stream(
            &self,
            request: tonic::Request<super::CreateLogStreamRequest>,
        ) -> std::result::Result<tonic::Response<super::LogStream>, tonic::Status>;
    }
    /// #### Introduction
    ///
    /// The Log Stream API manages LogStream resources which are used to stream
    /// writes and reads of an ordered sequence of bytes of unknown eventual length.
    ///
    /// Note that this is an API Interface and not an API Service, per the definitions
    /// at: https://cloud.google.com/apis/design/glossary
    ///
    /// Log Stream API supports the reading of unfinalized LogStreams either by
    /// seeking or in "tail" mode, for example by end-users browsing to a build
    /// result UI interested in seeing logs from a build action as soon as they are
    /// (or as they become) available.
    ///
    /// Reads and Writes of LogStreams are done via the Byte Stream API:
    /// https://cloud.google.com/dataproc/docs/reference/rpc/google.bytestream
    /// https://github.com/googleapis/googleapis/blob/master/google/bytestream/bytestream.proto
    ///
    /// #### Writing LogStreams
    ///
    /// LogStreams are written to via the Byte Stream API's `Write` RPC. Bytes
    /// written to LogStreams are expected to be committed and available for reading
    /// within a reasonable period of time (implementation-defined). Committed bytes
    /// to a LogStream cannot be overwritten, and finalized LogStreams - indicated by
    /// setting `finish_write` field in the final WriteRequest - also cannot be
    /// appended to.
    ///
    /// When calling the Byte Stream API's `Write` RPC to write LogStreams, writers
    /// must pass the `write_resource_name` of a LogStream as
    /// `ByteStream.WriteRequest.resource_name` rather than the LogStream's `name`.
    /// Separate resource names for reading and writing allows for broadcasting the
    /// read resource name widely while simultaneously ensuring that only writer(s)
    /// with knowledge of the write resource name may have written bytes to the
    /// LogStream.
    ///
    /// #### Reading LogStreams
    ///
    /// Use the Byte Stream API's `Read` RPC to read LogStreams. When reading
    /// finalized LogStreams the server will stream all contents of the LogStream
    /// starting at `ByteStream.ReadRequest.read_offset`.
    ///
    /// When reading unfinalized LogStreams the server must keep the streaming
    /// `ByteStream.Read` RPC open and send `ByteStream.ReadResponse` messages as
    /// more bytes become available or the LogStream is finalized.
    ///
    /// #### Example Multi-Party Read/Write Flow
    ///
    /// 1. LogStream Writer calls `CreateLogStream`
    /// 2. LogStream Writer publishes `LogStream.name`
    /// 3. LogStream Writer calls `ByteStream.Write` with
    ///    `LogStream.write_resource_name` as
    ///    `ByteStream.WriteRequest.resource_name`,
    ///    `ByteStream.WriteRequest.finish_write`=false.
    /// 4. LogStream Reader(s) call `ByteStream.Read` with the published
    ///    `LogStream.name` as `ByteStream.ReadRequest.resource_name`.
    /// 5. LogStream Service streams all committed bytes to LogStream Reader(s),
    ///    leave the stream open.
    /// 6. LogStream Writer calls `ByteStream.Write` with
    ///    `LogStream.write_resource_name` as
    ///    `ByteStream.WriteRequest.resource_name`,
    ///    `ByteStream.WriteRequest.finish_write`=true.
    /// 7. LogStream Service streams all remaining bytes to LogStream Reader(s),
    ///    terminates the stream.
    #[derive(Debug)]
    pub struct LogStreamServiceServer<T> {
        inner: Arc<T>,
        accept_compression_encodings: EnabledCompressionEncodings,
        send_compression_encodings: EnabledCompressionEncodings,
        max_decoding_message_size: Option<usize>,
        max_encoding_message_size: Option<usize>,
    }
    impl<T> LogStreamServiceServer<T> {
        pub fn new(inner: T) -> Self {
            Self::from_arc(Arc::new(inner))
        }
        pub fn from_arc(inner: Arc<T>) -> Self {
            Self {
                inner,
                accept_compression_encodings: Default::default(),
                send_compression_encodings: Default::default(),
                max_decoding_message_size: None,
                max_encoding_message_size: None,
            }
        }
        pub fn with_interceptor<F>(
            inner: T,
            interceptor: F,
        ) -> InterceptedService<Self, F>
        where
            F: tonic::service::Interceptor,
        {
            InterceptedService::new(Self::new(inner), interceptor)
        }
        /// Enable decompressing requests with the given encoding.
        #[must_use]
        pub fn accept_compressed(mut self, encoding: CompressionEncoding) -> Self {
            self.accept_compression_encodings.enable(encoding);
            self
        }
        /// Compress responses with the given encoding, if the client supports it.
        #[must_use]
        pub fn send_compressed(mut self, encoding: CompressionEncoding) -> Self {
            self.send_compression_encodings.enable(encoding);
            self
        }
        /// Limits the maximum size of a decoded message.
        ///
        /// Default: `4MB`
        #[must_use]
        pub fn max_decoding_message_size(mut self, limit: usize) -> Self {
            self.max_decoding_message_size = Some(limit);
            self
        }
        /// Limits the maximum size of an encoded message.
        ///
        /// Default: `usize::MAX`
        #[must_use]
        pub fn max_encoding_message_size(mut self, limit: usize) -> Self {
            self.max_encoding_message_size = Some(limit);
            self
        }
    }
    impl<T, B> tonic::codegen::Service<http::Request<B>> for LogStreamServiceServer<T>
    where
        T: LogStreamService,
        B: Body + std::marker::Send + 'static,
        B::Error: Into<StdError> + std::marker::Send + 'static,
    {
        type Response = http::Response<tonic::body::Body>;
        type Error = std::convert::Infallible;
        type Future = BoxFuture<Self::Response, Self::Error>;
        fn poll_ready(
            &mut self,
            _cx: &mut Context<'_>,
        ) -> Poll<std::result::Result<(), Self::Error>> {
            Poll::Ready(Ok(()))
        }
        fn call(&mut self, req: http::Request<B>) -> Self::Future {
            match req.uri().path() {
                "/build.bazel.remote.logstream.v1.LogStreamService/CreateLogStream" => {
                    #[allow(non_camel_case_types)]
                    struct CreateLogStreamSvc<T: LogStreamService>(pub Arc<T>);
                    impl<
                        T: LogStreamService,
                    > tonic::server::UnaryService<super::CreateLogStreamRequest>
                    for CreateLogStreamSvc<T> {
                        type Response = super::LogStream;
                        type Future = BoxFuture<
                            tonic::Response<Self::Response>,
                            tonic::Status,
                        >;
                        fn call(
                            &mut self,
                            request: tonic::Request<super::CreateLogStreamRequest>,
                        ) -> Self::Future {
                            let inner = Arc::clone(&self.0);
                            let fut = async move {
                                <T as LogStreamService>::create_log_stream(&inner, request)
                                    .await
                            };
                            Box::pin(fut)
                        }
                    }
                    let accept_compression_encodings = self.accept_compression_encodings;
                    let send_compression_encodings = self.send_compression_encodings;
                    let max_decoding_message_size = self.max_decoding_message_size;
                    let max_encoding_message_size = self.max_encoding_message_size;
                    let inner = self.inner.clone();
                    let fut = async move {
                        let method = CreateLogStreamSvc(inner);
                        let codec = tonic::codec::ProstCodec::default();
                        let mut grpc = tonic::server::Grpc::new(codec)
                            .apply_compression_config(
                                accept_compression_encodings,
                                send_compression_encodings,
                            )
                            .apply_max_message_size_config(
                                max_decoding_message_size,
                                max_encoding_message_size,
                            );
                        let res = grpc.unary(method, req).await;
                        Ok(res)
                    };
                    Box::pin(fut)
                }
                _ => {
                    Box::pin(async move {
                        let mut response = http::Response::new(
                            tonic::body::Body::default(),
                        );
                        let headers = response.headers_mut();
                        headers
                            .insert(
                                tonic::Status::GRPC_STATUS,
                                (tonic::Code::Unimplemented as i32).into(),
                            );
                        headers
                            .insert(
                                http::header::CONTENT_TYPE,
                                tonic::metadata::GRPC_CONTENT_TYPE,
                            );
                        Ok(response)
                    })
                }
            }
        }
    }
    impl<T> Clone for LogStreamServiceServer<T> {
        fn clone(&self) -> Self {
            let inner = self.inner.clone();
            Self {
                inner,
                accept_compression_encodings: self.accept_compression_encodings,
                send_compression_encodings: self.send_compression_encodings,
                max_decoding_message_size: self.max_decoding_message_size,
                max_encoding_message_size: self.max_encoding_message_size,
            }
        }
    }
    /// Generated gRPC service name
    pub const SERVICE_NAME: &str = "build.bazel.remote.logstream.v1.LogStreamService";
    impl<T> tonic::server::NamedService for LogStreamServiceServer<T> {
        const NAME: &'static str = SERVICE_NAME;
    }
}
